{"cells":[{"cell_type":"code","source":["!wget https://data.cityofnewyork.us/api/views/hvrh-b6nb/rows.csv?accessType=DOWNLOAD&bom=true&query=select+*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAWPF420-v6N","executionInfo":{"status":"ok","timestamp":1697016104618,"user_tz":-330,"elapsed":1017963,"user":{"displayName":"Mihir Waykole","userId":"07765196864667975622"}},"outputId":"10bee31f-21b1-4bdc-fbf2-8a6e32020014"},"id":"CAWPF420-v6N","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-11 09:04:46--  https://data.cityofnewyork.us/api/views/hvrh-b6nb/rows.csv?accessType=DOWNLOAD\n","Resolving data.cityofnewyork.us (data.cityofnewyork.us)... 52.206.140.199, 52.206.68.26, 52.206.140.205\n","Connecting to data.cityofnewyork.us (data.cityofnewyork.us)|52.206.140.199|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/csv]\n","Saving to: ‘rows.csv?accessType=DOWNLOAD’\n","\n","rows.csv?accessType     [          <=>       ]   2.08G  1.75MB/s    in 16m 57s \n","\n","2023-10-11 09:21:43 (2.09 MB/s) - ‘rows.csv?accessType=DOWNLOAD’ saved [2229139706]\n","\n"]}]},{"cell_type":"code","execution_count":1,"id":"071cb895","metadata":{"id":"071cb895","executionInfo":{"status":"ok","timestamp":1697016861942,"user_tz":-330,"elapsed":666,"user":{"displayName":"Mihir Waykole","userId":"07765196864667975622"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"b81bcd7e","metadata":{"id":"b81bcd7e"},"outputs":[],"source":["data = pd.read_csv('data.csv')"]},{"cell_type":"code","execution_count":null,"id":"a82e7b8e","metadata":{"id":"a82e7b8e"},"outputs":[],"source":["data.columns"]},{"cell_type":"code","execution_count":null,"id":"8538ed7c","metadata":{"id":"8538ed7c"},"outputs":[],"source":["import pandas as pd\n","from itertools import combinations\n","\n","df = pd.read_csv('data.csv')\n","\n","quasi_identifiers = ['Pickup_longitude', 'Pickup_latitude', 'Dropoff_longitude', 'Dropoff_latitude', 'Passenger_count']\n","\n","k = 3\n","\n","def find_k_anonymous_groups(df, quasi_identifiers, k):\n","    groups = []\n","    for _, group in df.groupby(quasi_identifiers):\n","        if len(group) >= k:\n","            groups.append(group)\n","    return groups\n","\n","\n","k_anonymous_groups = find_k_anonymous_groups(df, quasi_identifiers, k)\n","\n","\n","k_anonymized_df = pd.concat(k_anonymous_groups)\n","\n","k_anonymized_df.to_csv('k_anonymized_dataset_full.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"id":"942fd1e0","metadata":{"id":"942fd1e0"},"outputs":[],"source":["import pandas as pd\n","\n","# Load your dataset\n","df = pd.read_csv('k_anonymized_dataset_full.csv')\n","\n","numerical_attributes = ['Trip_distance', 'Fare_amount', 'Extra', 'MTA_tax', 'Tip_amount', 'Tolls_amount', 'Total_amount']\n","for attr in numerical_attributes:\n","    df[attr] = pd.to_numeric(df[attr], errors='coerce')  # Convert to float, coerce errors to NaN\n","    df[attr] = (df[attr] - df[attr].min()) / (df[attr].max() - df[attr].min())\n","\n","\n","quasi_identifiers = ['Pickup_longitude', 'Pickup_latitude', 'Dropoff_longitude', 'Dropoff_latitude', 'Passenger_count']\n","sensitive_attribute = 'Fare_amount'\n","\n","L = 2\n","\n","def generalize_fare(fare):\n","    return round(fare)\n","\n","def apply_l_diversity(group_data):\n","    unique_sensitive_values = group_data[sensitive_attribute].unique()\n","    if len(unique_sensitive_values) < L:\n","        print(f'{unique_sensitive_values} of {L}\\n')\n","        group_data[sensitive_attribute] = generalize_fare(group_data[sensitive_attribute])\n","    return group_data\n","\n","\n","grouped = df.groupby(quasi_identifiers)\n","\n","df_anonymized = grouped.apply(apply_l_diversity).reset_index(drop=True)\n","\n","print('\\nDone')\n","df_anonymized.to_csv('k_anonymized_l_diversity_dataset.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"id":"ce295827","metadata":{"id":"ce295827","outputId":"8dc8fd78-bc64-4f96-b9dd-91045205328c"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\OMEN\\AppData\\Local\\Temp\\ipykernel_6784\\3856959818.py:44: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n","To preserve the previous behavior, use\n","\n","\t>>> .groupby(..., group_keys=False)\n","\n","To adopt the future behavior and silence this warning, use \n","\n","\t>>> .groupby(..., group_keys=True)\n","  df_anonymized = grouped.apply(apply_l_diversity_with_perturbation).reset_index(drop=True)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load your dataset\n","df = pd.read_csv('k_anonymized_dataset_full.csv')\n","\n","# Define your quasi-identifiers and sensitive attribute\n","quasi_identifiers = ['Pickup_longitude', 'Pickup_latitude', 'Dropoff_longitude', 'Dropoff_latitude', 'Passenger_count']\n","sensitive_attribute = 'Fare_amount'\n","\n","# Define L-diversity parameter\n","L = 3  # Adjust according to your privacy requirements\n","\n","# Function to apply L-diversity with data perturbation\n","def apply_l_diversity_with_perturbation(group_data):\n","    unique_sensitive_values = group_data[sensitive_attribute].unique()\n","    num_unique_sensitive_values = len(unique_sensitive_values)\n","\n","    if num_unique_sensitive_values < L:\n","        # Convert the sensitive attribute to a numeric type\n","        group_data[sensitive_attribute] = pd.to_numeric(group_data[sensitive_attribute], errors='coerce')\n","\n","        # Apply data perturbation to achieve L-diversity\n","        if num_unique_sensitive_values > 0:\n","            # Calculate the amount of noise to add\n","            noise_std_dev = (group_data[sensitive_attribute].max() - group_data[sensitive_attribute].min()) / 10  # Adjust as needed\n","\n","            # Generate random noise\n","            noise = np.random.normal(scale=noise_std_dev, size=len(group_data))\n","\n","            # Perturb the sensitive attribute with noise\n","            group_data[sensitive_attribute] = group_data[sensitive_attribute] + noise\n","\n","        # Continue with other transformations or suppressions as needed\n","\n","    return group_data\n","\n","# Group the data by quasi-identifiers\n","grouped = df.groupby(quasi_identifiers)\n","\n","\n","\n","# Apply L-diversity with data perturbation to each group\n","df_anonymized = grouped.apply(apply_l_diversity_with_perturbation).reset_index(drop=True)\n","\n","# Evaluate and Validate\n","# Perform re-identification risk analysis and statistical tests\n","\n","# Post-Processing (if needed)\n","# Further data cleaning or adjustments\n","\n","# Save the anonymized dataset\n","df_anonymized.to_csv('l_diversity_with_perturbation_dataset.csv', index=False)\n"]},{"cell_type":"code","execution_count":3,"id":"be1bf200","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"be1bf200","executionInfo":{"status":"ok","timestamp":1697017137200,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mihir Waykole","userId":"07765196864667975622"}},"outputId":"dedbf575-1095-455e-b0d0-62d2799d1195"},"outputs":[{"output_type":"stream","name":"stdout","text":["   Age Gender GeneralizedZIP  Count\n","0    1    foo            foo      2\n","   Age Gender GeneralizedZIP  Count\n","0   25      M         123XXX      2\n","1   27      F         123XXX      1\n","2   32      F         543XXX      1\n","3   45      M         678XXX      1   Age Gender GeneralizedZIP  Count\n","0   25      F         543XXX      1\n","1   27      M         123XXX      1\n","2   32      F         543XXX      1\n","3   45      M         678XXX      1\n","\n","   ID  Age Gender    ZIP GeneralizedZIP\n","0   1   25      M  12345        General\n","1   2   32      F  54321        General\n","2   3   25      M  12345        General\n","3   4   45      M  67890        General\n","4   5   27      F  12345        General\n","5   6   32      F  54321        General\n","6   7   45      M  67890        General\n","7   8   27      M  12345        General\n","8   9   25      F  54321        General\n"]}],"source":["import dask.dataframe as dd\n","import pandas as pd\n","\n","# Sample dataset with quasi-identifiers (e.g., age, gender, and ZIP code)\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n","    'Age': [25, 32, 25, 45, 27, 32, 45, 27, 25],\n","    'Gender': ['M', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F'],\n","    'ZIP': ['12345', '54321', '12345', '67890', '12345', '54321', '67890', '12345', '54321']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Define the value of k for k-anonymity\n","k = 3\n","\n","# Function to perform generalization (e.g., by replacing ZIP codes with a general region)\n","def generalize_zip(zip_code):\n","    return zip_code[:3] + \"XXX\"\n","\n","# Initialize a new column for generalized ZIP codes\n","df['GeneralizedZIP'] = df['ZIP'].apply(generalize_zip)\n","\n","# Use Dask to read and process the data in chunks\n","ddf = dd.from_pandas(df, npartitions=2)  # Set the number of partitions for parallel processing\n","\n","def k_anonymize(partition):\n","    # Group the partitioned data by quasi-identifiers and count the occurrences\n","    grouped = partition.groupby(['Age', 'Gender', 'GeneralizedZIP']).size().reset_index(name='Count')\n","    # Identify groups that do not meet the k-anonymity requirement\n","    non_k_anonymous_groups = grouped[grouped['Count'] < k]\n","\n","    # Anonymize the non-k-anonymous groups in this partition\n","    for idx, row in non_k_anonymous_groups.iterrows():\n","        mask = (partition['Age'] == row['Age']) & (partition['Gender'] == row['Gender']) & (partition['GeneralizedZIP'] == row['GeneralizedZIP'])\n","        partition.loc[mask, 'GeneralizedZIP'] = \"General\"\n","    return partition\n","\n","# Apply k-anonymization to each partition\n","anonymized_ddf = ddf.map_partitions(k_anonymize)\n","\n","# Compute and store the result to a new Dask DataFrame\n","anonymized_df = anonymized_ddf.compute()\n","\n","# Display the anonymized dataset\n","print(anonymized_df)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}